{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data = pd.read_csv('LetsCheck.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8807\n",
      "Validation Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.87      1127\n",
      "           1       0.90      0.89      0.90      1514\n",
      "           2       0.85      0.88      0.87       359\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.87      0.88      0.88      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n",
      "Test Accuracy: 0.8793\n",
      "Test Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      1107\n",
      "           1       0.90      0.89      0.89      1496\n",
      "           2       0.90      0.88      0.89       397\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.88      0.88      0.88      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n",
      "Feature Importances: {'Gender': 0.03559045576780508, 'Age': 0.1956302418289466, 'Hairline Pattern': 0.021359144237299916, 'Hair Fall Rate': 0.07757835806651975, 'Nutrition': 0.06703840988844512, 'Chemical Product Usage': 0.07468952828908859, 'Genetics': 0.02942876065940857, 'Past Chronic Illness': 0.11586167782647806, 'Sleep Disturbance': 0.10939772549376842, 'Water Quality Issue': 0.09854498344921345, 'Stress': 0.07240097029457705, 'Food Habit': 0.06917314842350043, 'Hormonal Changes': 0.013611508396909331, 'Hair Care Habits': 0.009715783303827467, 'Smoking': 0.009979304074212261}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd  # Make sure this is imported\n",
    "\n",
    "# Important Features (Assigning Higher Weights)\n",
    "feature_weights = {\n",
    "    'Hair Fall Rate': 19,  # Very Important Feature\n",
    "    'Genetics': 2,  # Important\n",
    "    'Stress': 2,  # Important\n",
    "    'Hormonal Changes': 2,  # Important\n",
    "    'Sleep Disturbance': 2,  # Important\n",
    "}\n",
    "\n",
    "# Prepare Features and Target\n",
    "X_risk = main_data.drop('Label', axis=1)  # Features\n",
    "y_risk = main_data['Label']  # Target variable\n",
    "\n",
    "# Apply feature importance weights (Multiply Selected Columns)\n",
    "for feature, weight in feature_weights.items():\n",
    "    if feature in X_risk.columns:\n",
    "        X_risk[feature] = X_risk[feature] * weight  # Boost its value\n",
    "\n",
    "# First split: 80% train, 20% temp (which will be split into validation and test)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_risk , y_risk , test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: 50% validation, 50% test from the temp set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize SMOTE (to handle class imbalance)\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Apply SMOTE and preserve feature names\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "X_train_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)  # This is the key change\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier on the resampled training data\n",
    "rf_classifier.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_class_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "# Display the results for the validation set\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "print(\"Validation Classification Report:\")\n",
    "print(val_class_report)\n",
    "\n",
    "# Predict on the test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_class_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "# Display the results for the test set\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"Test Classification Report:\")\n",
    "print(test_class_report)\n",
    "\n",
    "# Show feature importances\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_importance_dict = dict(zip(X_risk.columns, importances))\n",
    "\n",
    "print(\"Feature Importances:\", feature_importance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Metrics:\n",
      "Mean Squared Error: 0.16\n",
      "Root Mean Squared Error: 0.40\n",
      "R² Score: 0.6246\n",
      "Mean Absolute Error: 4.084699210535965\n",
      "\n",
      "Test Set Metrics:\n",
      "Mean Squared Error: 51.12\n",
      "Root Mean Squared Error: 7.15\n",
      "R² Score: 0.6211\n",
      "Mean Absolute Error: 4.13\n",
      "\n",
      "Feature Importances:\n",
      "Hair Fall Rate: 0.3791\n",
      "Nutrition: 0.1981\n",
      "Hairline Pattern: 0.1028\n",
      "Gender: 0.0681\n",
      "Label: 0.0447\n",
      "Stress: 0.0436\n",
      "Chemical Product Usage: 0.0428\n",
      "Water Quality Issue: 0.0292\n",
      "Genetics: 0.0261\n",
      "Hair Care Habits: 0.0148\n",
      "Smoking: 0.0139\n",
      "Hormonal Changes: 0.0113\n",
      "Food Habit: 0.0095\n",
      "Sleep Disturbance: 0.0091\n",
      "Past Chronic Illness: 0.0068\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Prepare Features and Target\n",
    "X_age = main_data.drop(['Age'], axis=1)  # Features (assuming 'Age_Of_Onset' is your target)\n",
    "y_age = main_data['Age']  # Target variable for age prediction\n",
    "\n",
    "\n",
    "\n",
    "# First split: 80% train, 20% temp (which will be split into validation and test)\n",
    "X_train_age, X_temp_age, y_train_age, y_temp_age = train_test_split(X_age, y_age, test_size=0.2, random_state=42)\n",
    "\n",
    "# Second split: 50% validation, 50% test from the temp set\n",
    "X_val_age, X_test_age, y_val_age, y_test_age = train_test_split(X_temp_age, y_temp_age, test_size=0.5, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "# Train the regressor\n",
    "rf_regressor.fit(X_train_age, y_train_age)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred_age = rf_regressor.predict(X_val_age)\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_mse = mean_squared_error(y_val, y_val_pred)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Display the results for the validation set\n",
    "print(\"Validation Set Metrics:\")\n",
    "print(f\"Mean Squared Error: {val_mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {val_rmse:.2f}\")\n",
    "print(f\"R² Score: {val_r2:.4f}\")\n",
    "\n",
    "# Calculate Mean Absolute Error\n",
    "\n",
    "\n",
    "\n",
    "error = mean_absolute_error(y_val_age, y_val_pred_age)\n",
    "print(f\"Mean Absolute Error: {error}\")\n",
    "\n",
    " \n",
    "# Predict on the test set\n",
    "y_test_pred_age= rf_regressor.predict(X_test_age)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_mse = mean_squared_error(y_test_age, y_test_pred_age)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test_age, y_test_pred_age)\n",
    "test_mae = mean_absolute_error(y_test_age, y_test_pred_age)\n",
    "\n",
    "# Display the results for the test set\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {test_rmse:.2f}\")\n",
    "print(f\"R² Score: {test_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {test_mae:.2f}\")\n",
    "\n",
    "# Show feature importances\n",
    "importances = rf_regressor.feature_importances_\n",
    "feature_importance_dict = dict(zip(X_age.columns, importances))\n",
    "\n",
    "# Sort and display feature importances\n",
    "sorted_importances = dict(sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in sorted_importances.items():\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 675 candidates, totalling 3375 fits\n",
      "\n",
      "Best Parameters:\n",
      "max_depth: 30\n",
      "max_features: None\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 5\n",
      "n_estimators: 500\n",
      "\n",
      "Test Set Metrics:\n",
      "Mean Squared Error: 51.12\n",
      "Root Mean Squared Error: 7.15\n",
      "R² Score: 0.6211\n",
      "Mean Absolute Error: 4.13\n",
      "\n",
      "Feature Importances:\n",
      "Hair Fall Rate: 0.3815\n",
      "Nutrition: 0.1990\n",
      "Hairline Pattern: 0.1043\n",
      "Gender: 0.0660\n",
      "Label: 0.0455\n",
      "Stress: 0.0423\n",
      "Chemical Product Usage: 0.0419\n",
      "Water Quality Issue: 0.0301\n",
      "Genetics: 0.0259\n",
      "Hair Care Habits: 0.0144\n",
      "Smoking: 0.0132\n",
      "Hormonal Changes: 0.0104\n",
      "Food Habit: 0.0096\n",
      "Sleep Disturbance: 0.0094\n",
      "Past Chronic Illness: 0.0065\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Define parameter grid with corrected max_features values\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 40],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]  # Removed 'auto' as it's no longer supported\n",
    "}\n",
    "\n",
    "# Initialize base Random Forest model\n",
    "rf_base = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_base,\n",
    "    param_grid=param_grid,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    error_score='raise'  # This will help identify any other potential issues\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV using training data\n",
    "grid_search.fit(X_train_age, y_train_age)\n",
    "\n",
    "# Get best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = best_model.predict(X_test_age)\n",
    "\n",
    "# Calculate metrics\n",
    "test_mse = mean_squared_error(y_test_age, y_test_pred_age)\n",
    "test_rmse = np.sqrt(test_mse)\n",
    "test_r2 = r2_score(y_test_age, y_test_pred_age)\n",
    "test_mae = mean_absolute_error(y_test_age, y_test_pred_age)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"\\nBest Parameters:\")\n",
    "for param, value in grid_search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")\n",
    "\n",
    "# Print test set metrics\n",
    "print(\"\\nTest Set Metrics:\")\n",
    "print(f\"Mean Squared Error: {test_mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {test_rmse:.2f}\")\n",
    "print(f\"R² Score: {test_r2:.4f}\")\n",
    "print(f\"Mean Absolute Error: {test_mae:.2f}\")\n",
    "\n",
    "# Get and print feature importances\n",
    "importances = best_model.feature_importances_\n",
    "feature_importance_dict = dict(zip(X_test_age.columns, importances))\n",
    "sorted_importances = dict(sorted(feature_importance_dict.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "print(\"\\nFeature Importances:\")\n",
    "for feature, importance in sorted_importances.items():\n",
    "    print(f\"{feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters for Random Forest: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Cross-Validation Accuracy (on Training Set): 0.8961578400830738\n",
      "Validation Set Results:\n",
      "Accuracy: 0.887\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87      1127\n",
      "           1       0.90      0.90      0.90      1514\n",
      "           2       0.88      0.88      0.88       359\n",
      "\n",
      "    accuracy                           0.89      3000\n",
      "   macro avg       0.88      0.88      0.88      3000\n",
      "weighted avg       0.89      0.89      0.89      3000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 982  124   21]\n",
      " [ 126 1364   24]\n",
      " [  19   25  315]]\n",
      "Test Set Results:\n",
      "Accuracy: 0.8816666666666667\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86      1107\n",
      "           1       0.89      0.89      0.89      1496\n",
      "           2       0.93      0.88      0.90       397\n",
      "\n",
      "    accuracy                           0.88      3000\n",
      "   macro avg       0.89      0.88      0.88      3000\n",
      "weighted avg       0.88      0.88      0.88      3000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 961  130   16]\n",
      " [ 148 1336   12]\n",
      " [  18   31  348]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10, 15],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),  # Base classifier\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=3,  # 3-fold cross-validation on the training set\n",
    "    scoring='accuracy',  # Metric to optimize\n",
    "    n_jobs=-1  # Use all available CPU cores\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV on the resampled training data\n",
    "grid_search_rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and best score (from cross-validation on the training set)\n",
    "print(\"Best Parameters for Random Forest:\", grid_search_rf.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy (on Training Set):\", grid_search_rf.best_score_)\n",
    "\n",
    "# Get the best model from GridSearchCV\n",
    "best_rf_model = grid_search_rf.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "y_val_pred = best_rf_model.predict(X_val)\n",
    "print(\"Validation Set Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val, y_val_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_val_pred))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_test_pred = best_rf_model.predict(X_test)\n",
    "print(\"Test Set Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_test_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_user_input():\n",
    "    user_input = {}\n",
    "    \n",
    "    print(\"Please enter the following details:\")\n",
    "\n",
    "    user_input['Gender'] = int(input(\"Gender (0: Female, 1: Male, 2: Other): \"))\n",
    "    user_input['Age'] = int(input(\"Current Age (e.g., 22, 23, etc.): \"))\n",
    "    user_input['Hairline Pattern'] = int(input(\"Hairline Pattern (0: Normal, 1: Receding, 2, 3, 4, 5: Other variations): \"))\n",
    "    user_input['Hair Fall Rate'] = float(input(\"Hair Fall Rate (e.g., 50 strands per day): \"))\n",
    "    user_input['Nutrition'] = float(input(\"Nutrition Level (1-10, 10 being excellent): \"))\n",
    "    user_input['Chemical Product Usage'] = int(input(\"Chemical Product Usage (0: No, 1, 2, 3: Varying levels of use): \"))\n",
    "    user_input['Genetics'] = int(input(\"Family History of Hair Loss (0: No, 1: Yes, 2: yes ): \"))\n",
    "    user_input['Past Chronic Illness'] = int(input(\"Past Chronic Illness (0: No, 1: Yes, 2: Severe): \"))\n",
    "    user_input['Sleep Disturbance'] = int(input(\"Sleep Disturbance (0: No, 1: Yes, 2: Severe issues): \"))\n",
    "    user_input['Water Quality Issue'] = int(input(\"Poor Water Quality (0: No, 1: Yes, 2: Very bad): \"))\n",
    "    user_input['Stress'] = int(input(\"Stress Levels (0: Low, 1: Medium, 2: High, 3: Extreme): \"))\n",
    "    user_input['Food Habit'] = int(input(\"Food Habit (0: Healthy, 1: Unhealthy, 2: Junk food, 3: Worst diet): \"))\n",
    "    user_input['Hormonal Changes'] = int(input(\"Hormonal Imbalance (0: No, 1: Yes): \"))\n",
    "    user_input['Hair Care Habits'] = int(input(\"Poor Hair Care Habits (0: No, 1: Yes): \"))\n",
    "    user_input['Smoking'] = int(input(\"Smoking (0: No, 1: Yes): \"))\n",
    "\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def adjust_age_based_on_features(user_input, predicted_age):\n",
    "    # Adjusting the predicted age based on the high-importance features\n",
    "    weight_factors = {\n",
    "        \"Chemical Product Usage\": 1.4,  # This could be a factor to increase the age slightly\n",
    "        \"Genetics\": 1.3,  # Higher weight for family history\n",
    "        \"Past Chronic Illness\": 1.1,  # Slight adjustment if there's a history of illness\n",
    "        \"Sleep Disturbance\": 1.2,  # Sleep disturbance increases the risk slightly\n",
    "        \"Water Quality Issue\": 1.1,  # Water quality issue could also slightly increase age prediction\n",
    "        \"Stress\": 1.2,  # Stress can accelerate hair fall, so adjust accordingly\n",
    "        \"Food Habit\": 1.3  # Poor food habits could accelerate hair loss\n",
    "    }\n",
    "    \n",
    "    adjusted_age = predicted_age\n",
    "    for feature, weight in weight_factors.items():\n",
    "        if user_input[feature] == 2:  # Higher value means worse factor (e.g., 2 for high usage or poor quality)\n",
    "            adjusted_age += 1  # You can modify this factor based on how much influence you want to give each feature\n",
    "    \n",
    "    return adjusted_age\n",
    "\n",
    "def predict_hair_fall_risk(model, scaler, X_train_resampled, y_train_resampled):\n",
    "    # Get user input details\n",
    "    user_input = get_user_input()  # Assume a function to collect user input as before\n",
    "\n",
    "    # Define the feature order\n",
    "    feature_order = ['Gender', 'Age', 'Hairline Pattern', 'Hair Fall Rate', 'Nutrition',\n",
    "                     'Chemical Product Usage', 'Genetics', 'Past Chronic Illness',\n",
    "                     'Sleep Disturbance', 'Water Quality Issue', 'Stress', 'Food Habit',\n",
    "                     'Hormonal Changes', 'Hair Care Habits', 'Smoking']\n",
    "    \n",
    "    # Prepare the user input as a feature array\n",
    "    user_data = np.array([[user_input[feature] for feature in feature_order]])\n",
    "    \n",
    "    # Scale user input if a scaler is provided\n",
    "    if scaler:\n",
    "        user_data = scaler.transform(user_data)\n",
    "\n",
    "    # Make prediction for risk level\n",
    "    prediction = model.predict(user_data)[0]\n",
    "    \n",
    "    # Map the prediction to risk level (0 = Low, 1 = Medium, 2 = High)\n",
    "    risk_mapping = {0: \"Low Risk\", 1: \"Medium Risk\", 2: \"High Risk\"}\n",
    "    risk_level = risk_mapping.get(prediction, \"Unknown\")\n",
    "\n",
    "    # Now, using the 'Label' column from y_train_resampled to predict the age when hair loss might start\n",
    "    user_age = user_input[\"Age\"]\n",
    "    \n",
    "    if risk_level in [\"High Risk\", \"Medium Risk\"]:\n",
    "        # Filter the dataset based on the predicted risk level (using y_train_resampled and X_train_resampled)\n",
    "        risk_ages = X_train_resampled[y_train_resampled == prediction]['Age']\n",
    "        \n",
    "        # Calculate the average age for people in that risk category\n",
    "        avg_age = risk_ages.mean()  # Average age of people who experienced the same risk level\n",
    "\n",
    "        # For Medium Risk, calculate average first, then add 5 years\n",
    "        if risk_level == \"Medium Risk\":\n",
    "            predicted_age = (avg_age + user_age) / 2  # First calculate average\n",
    "            predicted_age += 5  # Then add 5 years to the predicted age\n",
    "\n",
    "        # For High Risk, calculate without any additional years\n",
    "        elif risk_level == \"High Risk\":\n",
    "            predicted_age = (avg_age + user_age) / 2\n",
    "\n",
    "        # Adjust age based on important features\n",
    "        adjusted_age = adjust_age_based_on_features(user_input, predicted_age)\n",
    "\n",
    "        print(f\"\\nPredicted Hair Fall Risk: {risk_level}\")\n",
    "        print(f\"Estimated Age When Hair Fall Might Start: {adjusted_age:.2f}\")\n",
    "        years = int(adjusted_age)\n",
    "        months = round((adjusted_age - years) * 12)\n",
    "        print(f\"Estimated Age When Hair Fall Might Start: {years} years and {months} months\")\n",
    "    \n",
    "    else:\n",
    "        # For low risk, no prediction is required.\n",
    "        print(f\"\\nPredicted Hair Fall Risk: {risk_level}\")\n",
    "        print(\"No significant risk predicted for hair fall. However, it's important to care for your hair health to avoid future problems.\")\n",
    "    return risk_level\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hair_fall_risk_age(risk_model, scaler, X_train_resampled, y_train_resampled, best_model):\n",
    "    # Get user input details\n",
    "    user_input = get_user_input()\n",
    "\n",
    "    # Define the feature order for risk prediction (including Age)\n",
    "    feature_order_risk = ['Gender', 'Age', 'Hairline Pattern', 'Hair Fall Rate', 'Nutrition',\n",
    "                          'Chemical Product Usage', 'Genetics', 'Past Chronic Illness',\n",
    "                          'Sleep Disturbance', 'Water Quality Issue', 'Stress', 'Food Habit',\n",
    "                          'Hormonal Changes', 'Hair Care Habits', 'Smoking']\n",
    "    \n",
    "    # Create DataFrame for risk prediction\n",
    "    user_data_risk = pd.DataFrame([user_input], columns=feature_order_risk)\n",
    "    \n",
    "    # Make prediction for risk level\n",
    "    risk_prediction = risk_model.predict(user_data_risk)[0]\n",
    "    \n",
    "    # Map the prediction to risk level (0 = Low, 1 = Medium, 2 = High)\n",
    "    risk_mapping = {0: \"Low Risk\", 1: \"Medium Risk\", 2: \"High Risk\"}\n",
    "    risk_level = risk_mapping.get(risk_prediction, \"Unknown\")\n",
    "    \n",
    "    if risk_level in [\"High Risk\", \"Medium Risk\"]:\n",
    "        # Prepare input data for age prediction\n",
    "        # Drop 'Age' (target variable) and add predicted 'Risk' as a feature\n",
    "        age_features = user_data_risk.drop('Age', axis=1)\n",
    "        age_features['Label'] = risk_prediction  # Add predicted risk as a feature\n",
    "        \n",
    "        # Ensure the feature order matches what was used during training of best_model\n",
    "        if hasattr(best_model, 'feature_names_in_'):\n",
    "            age_features = age_features[best_model.feature_names_in_]\n",
    "        \n",
    "        # Predict age using the best_model\n",
    "        predicted_age = best_model.predict(age_features)[0]\n",
    "        \n",
    "        # Get feature importance for age prediction\n",
    "        if hasattr(best_model, 'feature_importances_'):\n",
    "            feature_importance = dict(zip(age_features.columns, best_model.feature_importances_))\n",
    "            top_factors = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        else:\n",
    "            top_factors = []\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nPredicted Hair Fall Risk: {risk_level}\")\n",
    "        print(f\"Estimated Age of Hair Loss Onset: {predicted_age:.1f} years\")\n",
    "        print(\"\\nTop factors influencing the prediction:\")\n",
    "        for factor, importance in top_factors:\n",
    "            print(f\"- {factor}: {importance:.3f}\")\n",
    "    \n",
    "    else:\n",
    "        # For low risk, no prediction is required.\n",
    "        print(f\"\\nPredicted Hair Fall Risk: {risk_level}\")\n",
    "        print(\"No significant risk predicted for hair fall. However, it's important to care for your hair health to avoid future problems.\")\n",
    "    \n",
    "    return risk_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_product = pd.read_csv('main_product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Define risk-level specific keywords\n",
    "\n",
    "\n",
    "low_risk_keywords = [\n",
    "    \"shine enhancement\", \"scalp nourishment\", \"vitamin-rich\",\n",
    "    \"gentle cleansing\", \"moisturizing\", \"uv protection\", \"split end repair\", \n",
    "    \"natural oils\", \"hydration\", \"softening\", \"frizz control\", \"shine & gloss\", \n",
    "    \"detangling\", \"smoothness\", \"manageability\", \"silky-smooth\", \n",
    "    \"non-sticky formula\", \"humidity control\", \"lightweight\", \"heat protection\", \n",
    "    \"color protection\", \"daily care\", \"split ends prevention\", \"anti-frizz\", \n",
    "    \"straightening & smoothening\", \"conditioning\", \"nourishment\", \"volumizer\", \n",
    "    \"styling\"\n",
    "]\n",
    "\n",
    "\n",
    "medium_risk_keywords = [\n",
    "    \"thickening\", \"volume boost\", \"strengthening\", \"follicle stimulation\", \"anti-breakage\", \"scalp revitalization\",\n",
    "    \"keratin repair\", \"protein treatment\", \"hair growth support\", \"reducing hair fall\", \"damage repair\",\n",
    "    \"nourishment\", \"conditioning\", \"anti-frizz\", \"scalp health\", \"hair elasticity\", \"hair strength\", \"hair repair\",\n",
    "    \"anti-hair fall\",\n",
    "    \"growth stimulating\"\n",
    "]\n",
    "\n",
    "high_risk_keywords = [\n",
    "    \"follicle regeneration\", \"hair growth\", \"hair fall prevention\", \"nourishing repair\", \"damaged hair repair\",\n",
    "    \"restorative\", \"regrowth\", \"scalp repair\", \"hair loss\", \"thinning hair\", \"hair restoration\",\n",
    "    \"hair rejuvenation\", \n",
    "    \"intensive care\", \n",
    "      \"split-ends\",  \n",
    "      \"anti-hair fall\",\n",
    "     \"growth stimulating\",\n",
    "    \"hair revival\", \"regenerating serum\", \"hair reactivation\" \n",
    "]\n",
    "\n",
    "low_risk_keywords = list(set(low_risk_keywords))\n",
    "medium_risk_keywords = list(set(medium_risk_keywords))\n",
    "high_risk_keywords = list(set(high_risk_keywords))\n",
    "1\n",
    "\n",
    "def recommend_product(main_product):\n",
    "    # Get user risk level (using the predict_hair_fall_risk function)\n",
    "    risk_level = predict_hair_fall_risk(best_rf_model, None, X_train_resampled, y_train_resampled)  # Modify as needed to return the risk level directly\n",
    "\n",
    "    # Preprocess product details (cleaning, tokenization, vectorization)\n",
    "    product_details = main_product['Details']  # Assume this is the 'Details' column from your product dataset\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    product_vectors = vectorizer.fit_transform(product_details)\n",
    "\n",
    "    # Select keywords based on risk level\n",
    "    if risk_level == \"High Risk\":\n",
    "        keywords = high_risk_keywords\n",
    "    elif risk_level == \"Medium Risk\":\n",
    "        keywords = medium_risk_keywords\n",
    "    else:\n",
    "        keywords = low_risk_keywords\n",
    "\n",
    "    # Vectorize the user's condition based on the selected keywords\n",
    "    user_condition_vector = vectorizer.transform(keywords)\n",
    "\n",
    "    # Compute the cosine similarity between the user's keywords and product details\n",
    "    similarity_scores = cosine_similarity(user_condition_vector, product_vectors)\n",
    "\n",
    "    # Get the indices of the top 5 products based on the highest similarity scores\n",
    "    avg_similarity_scores = similarity_scores.mean(axis=0)  # Calculate the average similarity for each product\n",
    "    top_5_indices = np.argsort(avg_similarity_scores)[::-1][:5]  # Sort and get the top 5 products\n",
    "\n",
    "    # Print details of the top 5 recommended products\n",
    "    print(f\"Top 5 Recommended Products for Your Risk Level: {risk_level}\\n\")\n",
    "    \n",
    "    for i, idx in enumerate(top_5_indices):\n",
    "        recommended_product = main_product.iloc[idx]\n",
    "        print(f\"Rank {i+1}: {recommended_product['ProductsName']}\")\n",
    "        print(f\"Cost: {recommended_product['Product Cost']}\")\n",
    "        print(f\"Product Feedback: {recommended_product['Feedbacks']}\")\n",
    "        print('-' * 80)\n",
    "    return top_5_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_content_recommendations(selected_product_name, product_data, n_recommendations=5):\n",
    "    \"\"\"\n",
    "    Provides collaborative filtering based recommendations after user selects a product.\n",
    "    \n",
    "    Parameters:\n",
    "    selected_product_name: Name of the product selected by user from initial recommendations\n",
    "    product_data: DataFrame with columns [ProductsName, Product Cost, Feedbacks, Details]\n",
    "    n_recommendations: Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame containing recommended products\n",
    "    \"\"\"\n",
    "    # Create item features matrix using Details column\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    item_features = vectorizer.fit_transform(product_data['Details'])\n",
    "    \n",
    "    # Calculate item-item similarity matrix\n",
    "    item_similarity = cosine_similarity(item_features)\n",
    "    item_similarity_df = pd.DataFrame(\n",
    "        item_similarity,\n",
    "        index=product_data['ProductsName'],\n",
    "        columns=product_data['ProductsName']\n",
    "    )\n",
    "    \n",
    "    # Get similar products\n",
    "    similar_scores = item_similarity_df[selected_product_name].sort_values(ascending=False)\n",
    "    similar_products = similar_scores.index[1:n_recommendations+1].tolist()\n",
    "    \n",
    "    # Get full details of recommended products\n",
    "    recommendations = product_data[product_data['ProductsName'].isin(similar_products)].copy()\n",
    "    \n",
    "    # Add similarity score to recommendations\n",
    "    recommendations['SimilarityScore'] = recommendations['ProductsName'].map(similar_scores)\n",
    "    \n",
    "    # Sort by similarity score\n",
    "    recommendations = recommendations.sort_values('SimilarityScore', ascending=False)\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "def display_collaborative_recommendations(recommendations):\n",
    "    \"\"\"\n",
    "    Displays the collaborative filtering recommendations in a formatted way.\n",
    "    \n",
    "    Parameters:\n",
    "    recommendations: DataFrame containing recommended products\n",
    "    \"\"\"\n",
    "    print(\"\\nBased on your selection, you might also like:\\n\")\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        print(f\"Product: {row['ProductsName']}\")\n",
    "        print(f\"Cost: {row['Product Cost']}\")\n",
    "        print(f\"Product Feedback: {row['Feedbacks']}\")\n",
    "        print(f\"Similarity Score: {row['SimilarityScore']:.2f}\")\n",
    "        print('-' * 80)\n",
    "\n",
    "def complete_recommendation_workflow(product_data):\n",
    "    \"\"\"\n",
    "    Complete workflow combining initial risk-based recommendations and collaborative filtering.\n",
    "    \"\"\"\n",
    "    # Get top 5 recommended product indices\n",
    "    top_5_indices = recommend_product(product_data)  \n",
    "\n",
    "    if not isinstance(top_5_indices, (list, np.ndarray)) or len(top_5_indices) == 0:\n",
    "        print(\"No recommendations available. Please try again.\")\n",
    "        return\n",
    "    \n",
    "    # Get user selection\n",
    "    while True:\n",
    "        try:\n",
    "            selected_rank = int(input(f\"\\nPlease select a product by entering its rank (1-{min(5, len(top_5_indices))}): \"))\n",
    "            if 1 <= selected_rank <= min(5, len(top_5_indices)):\n",
    "                break\n",
    "            print(f\"Please enter a number between 1 and {min(5, len(top_5_indices))}.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number.\")\n",
    "\n",
    "    # Get the selected product's name using `.iloc`\n",
    "    selected_product_name = product_data.iloc[top_5_indices[selected_rank-1]]['ProductsName']\n",
    "\n",
    "    # Get and display collaborative recommendations\n",
    "    collab_recommendations = get_content_recommendations(selected_product_name, product_data)\n",
    "    display_collaborative_recommendations(collab_recommendations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_user_collaborative_recommendations(selected_product_name, product_data, n_recommendations=5):\n",
    "    \"\"\"\n",
    "    Provides user-collaborative filtering recommendations based on product feedback patterns.\n",
    "    \n",
    "    Parameters:\n",
    "    selected_product_name: Name of the product selected by user\n",
    "    product_data: DataFrame with columns [ProductsName, Product Cost, Feedbacks, Details]\n",
    "    n_recommendations: Number of recommendations to return\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame containing recommended products\n",
    "    \"\"\"\n",
    "    # Create item-feedback matrix using the Feedbacks column\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    feedback_features = vectorizer.fit_transform(product_data['Feedbacks'].astype(str))\n",
    "    \n",
    "    # Calculate item-item similarity based on feedback patterns\n",
    "    feedback_similarity = cosine_similarity(feedback_features)\n",
    "    feedback_similarity_df = pd.DataFrame(\n",
    "        feedback_similarity,\n",
    "        index=product_data['ProductsName'],\n",
    "        columns=product_data['ProductsName']\n",
    "    )\n",
    "    \n",
    "    # Get similar products based on feedback patterns\n",
    "    similar_scores = feedback_similarity_df[selected_product_name].sort_values(ascending=False)\n",
    "    similar_products = similar_scores.index[1:n_recommendations+1].tolist()\n",
    "    \n",
    "    # Get full details of recommended products\n",
    "    recommendations = product_data[product_data['ProductsName'].isin(similar_products)].copy()\n",
    "    recommendations['CollaborativeScore'] = recommendations['ProductsName'].map(similar_scores)\n",
    "    \n",
    "    return recommendations.sort_values('CollaborativeScore', ascending=False)\n",
    "\n",
    "def get_hybrid_recommendations(content_recommendations, collab_recommendations, product_data, weight_content=0.5):\n",
    "    \"\"\"\n",
    "    Combines content-based and feedback-based recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "    content_recommendations: DataFrame with content-based recommendations\n",
    "    collab_recommendations: DataFrame with feedback-based recommendations\n",
    "    product_data: Original product data\n",
    "    weight_content: Weight for content-based recommendations (0-1)\n",
    "    \n",
    "    Returns:\n",
    "    DataFrame with hybrid recommendations\n",
    "    \"\"\"\n",
    "    # Normalize similarity scores\n",
    "    content_recommendations['NormalizedContentScore'] = (\n",
    "        content_recommendations['SimilarityScore'] - content_recommendations['SimilarityScore'].min()\n",
    "    ) / (content_recommendations['SimilarityScore'].max() - content_recommendations['SimilarityScore'].min())\n",
    "    \n",
    "    collab_recommendations['NormalizedCollabScore'] = (\n",
    "        collab_recommendations['CollaborativeScore'] - collab_recommendations['CollaborativeScore'].min()\n",
    "    ) / (collab_recommendations['CollaborativeScore'].max() - collab_recommendations['CollaborativeScore'].min())\n",
    "    \n",
    "    # Combine recommendations\n",
    "    hybrid_recommendations = pd.concat([\n",
    "        content_recommendations[['ProductsName', 'NormalizedContentScore']],\n",
    "        collab_recommendations[['ProductsName', 'NormalizedCollabScore']]\n",
    "    ], axis=0)\n",
    "    \n",
    "    # Calculate hybrid score\n",
    "    hybrid_recommendations['HybridScore'] = hybrid_recommendations['NormalizedContentScore'].fillna(0) * weight_content + \\\n",
    "                                          hybrid_recommendations['NormalizedCollabScore'].fillna(0) * (1 - weight_content)\n",
    "    \n",
    "    # Get unique products with highest hybrid scores\n",
    "    hybrid_recommendations = hybrid_recommendations.groupby('ProductsName')['HybridScore'].max().reset_index()\n",
    "    hybrid_recommendations = hybrid_recommendations.sort_values('HybridScore', ascending=False)\n",
    "    \n",
    "    # Get full product details\n",
    "    final_recommendations = product_data[product_data['ProductsName'].isin(hybrid_recommendations['ProductsName'])].copy()\n",
    "    final_recommendations['HybridScore'] = final_recommendations['ProductsName'].map(\n",
    "        hybrid_recommendations.set_index('ProductsName')['HybridScore']\n",
    "    )\n",
    "    \n",
    "    return final_recommendations.sort_values('HybridScore', ascending=False)\n",
    "\n",
    "def display_recommendations(recommendations, recommendation_type=\"Recommendations\"):\n",
    "    \"\"\"\n",
    "    Displays recommendations in a formatted way.\n",
    "    \n",
    "    Parameters:\n",
    "    recommendations: DataFrame containing recommended products\n",
    "    recommendation_type: String indicating the type of recommendations being displayed\n",
    "    \"\"\"\n",
    "    print(f\"\\n{recommendation_type}:\\n\")\n",
    "    for idx, row in recommendations.iterrows():\n",
    "        print(f\"Product: {row['ProductsName']}\")\n",
    "        print(f\"Cost: {row['Product Cost']}\")\n",
    "        print(f\"Product Feedback: {row['Feedbacks']}\")\n",
    "        score_type = 'HybridScore' if 'HybridScore' in row else \\\n",
    "                    'CollaborativeScore' if 'CollaborativeScore' in row else 'SimilarityScore'\n",
    "        \n",
    "        print('-' * 80)\n",
    "\n",
    "def complete_hybrid_recommendation_workflow(product_data):\n",
    "    \"\"\"\n",
    "    Complete workflow combining content-based, feedback-based, and hybrid recommendations.\n",
    "    \n",
    "    Parameters:\n",
    "    user_input: User's initial input for content-based filtering\n",
    "    product_data: DataFrame with product information\n",
    "    \"\"\"\n",
    "    # Get initial content-based recommendations\n",
    "    top_5_indices = recommend_product(product_data)\n",
    "    \n",
    "    if not isinstance(top_5_indices, (list, np.ndarray)) or len(top_5_indices) == 0:\n",
    "        print(\"No recommendations available. Please try again.\")\n",
    "        return\n",
    "    \n",
    "    # Get user selection for content-based recommendations\n",
    "    while True:\n",
    "        try:\n",
    "            selected_rank = int(input(f\"\\nPlease select a product by entering its rank (1-{min(5, len(top_5_indices))}): \"))\n",
    "            if 1 <= selected_rank <= min(5, len(top_5_indices)):\n",
    "                break\n",
    "            print(f\"Please enter a number between 1 and {min(5, len(top_5_indices))}.\")\n",
    "        except ValueError:\n",
    "            print(\"Please enter a valid number.\")\n",
    "    \n",
    "    # Get selected product name\n",
    "    selected_product_name = product_data.iloc[top_5_indices[selected_rank-1]]['ProductsName']\n",
    "    \n",
    "    # Get content-based recommendations\n",
    "    content_recommendations = get_content_recommendations(selected_product_name, product_data)\n",
    "    display_recommendations(content_recommendations, \"Content-based Recommendations\")\n",
    "    \n",
    "    # Get feedback-based recommendations\n",
    "    collab_recommendations = get_user_collaborative_recommendations(selected_product_name, product_data)\n",
    "    display_recommendations(collab_recommendations, \"collaborative-based Recommendations\")\n",
    "    \n",
    "    # Get hybrid recommendations\n",
    "    hybrid_recommendations = get_hybrid_recommendations(content_recommendations, collab_recommendations, product_data)\n",
    "    display_recommendations(hybrid_recommendations, \"Hybrid Recommendations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the following details:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nitro\\anaconda3\\envs\\test_env\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted Hair Fall Risk: Medium Risk\n",
      "Estimated Age When Hair Fall Might Start: 33.46\n",
      "Estimated Age When Hair Fall Might Start: 33 years and 6 months\n",
      "Top 5 Recommended Products for Your Risk Level: Medium Risk\n",
      "\n",
      "Rank 1: ENAUNIQ Shikakai With Ritha Shampoo EXTRA Conditioner For Nourishing Soft & Smooth Hair  (1000 ml)\n",
      "Cost: 400.0\n",
      "Product Feedback: Excellent :- Very nice product I love it thanks for flipkart 🥰😍🙏 :- Awesome\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 2: look hair Onion Oil and Onion Shampoo  (500 ml)\n",
      "Cost: 638.4000000000001\n",
      "Product Feedback: Best products thank u flipcart :- Very Good product...Thank You Flipkart Excellent :- Good product\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 3: Kamill Herbal Shampoo And Conditioner With Tulsi, Amla & Shikkakai  (500 ml)\n",
      "Cost: 667.2\n",
      "Product Feedback: Nice\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 4: Khadi Mauri Amla Bhringraj Shampoo - Pack of 2  (420 ml)\n",
      "Cost: 478.4\n",
      "Product Feedback: Good, super :- Best shampoo for hairfall!! :- Nice shampoo..I love it😍\n",
      "--------------------------------------------------------------------------------\n",
      "Rank 5: Kesh King Scalp and Hair Medicine Ayurvedic Hairfall Expert Damage Repair Shampoo  (1000 ml)\n",
      "Cost: 512.0\n",
      "Product Feedback: Good product. Packaging is too large😂😂. :- I HAVE GOT THE PRODUCT TODAY.THIS QUALITY IS VERY GOOD EVEN I EXPECTEDHIGHLY RECOMMENDEDFRAGRANCE IS VERY SWEETAND IT IS GOOD FOR CAREING YOUR HAIR....... 👍👍👍👍 :- Good\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Content-based Recommendations:\n",
      "\n",
      "Product: HIMALAYA ANTI DANDRUFF COOLING MINT SHAMPOO 400ML  (400 ml)\n",
      "Cost: 401.6\n",
      "Product Feedback: Nice quality :- wow :- Nice product,  l like the product, when i was use to feel cooling skull,but quantity is very less\n",
      "--------------------------------------------------------------------------------\n",
      "Product: galway Rupabham Pro Keratin Shampoo+ Conditioner & Rupabham Pro-Keratin Hair Serum - Combo Pack  (250 ml)\n",
      "Cost: 1358.4\n",
      "Product Feedback: Fantastic product..... :- Good product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: look hair Onion Oil and Onion Shampoo  (500 ml)\n",
      "Cost: 638.4000000000001\n",
      "Product Feedback: Best products thank u flipcart :- Very Good product...Thank You Flipkart Excellent :- Good product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: KESUDA Amla Premium shampoo for better hair care  (600 ml)\n",
      "Cost: 454.4\n",
      "Product Feedback: Excellent and effective product for me ,very good composition, effect on hair is best, good alovera fragrance,stop my hairfall :- This product is 100% genuine  i can feel it , it give proper during 2 month , very  very good adorable product :- Superb daily care shampoo, super fast delivery I have big problem for dandruff and dryness ,this product resolve with in three month , first time I used this product and it give perfect result\n",
      "--------------------------------------------------------------------------------\n",
      "Product: KESUDA Aloevera Amla Shampoo for better hair care  (4 L)\n",
      "Cost: 1425.6\n",
      "Product Feedback: Excellent and effective product for me ,very good composition, effect on hair is best, good alovera fragrance,stop my hairfall :- This product is 100% genuine  i can feel it , it give proper during 2 month , very  very good adorable product :- Superb daily care shampoo, super fast delivery I have big problem for dandruff and dryness ,this product resolve with in three month , first time I used this product and it give perfect result\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "collaborative-based Recommendations:\n",
      "\n",
      "Product: TRICHUP Keratin Kit (Shampoo 200 ml, Conditioner 200 ml, Hair Cream 200 ml)  (3 Items in the set)\n",
      "Cost: 878.4000000000001\n",
      "Product Feedback: Very good :- Good product :- Thanks Flipkart nice product I love it\n",
      "--------------------------------------------------------------------------------\n",
      "Product: Oshea Herbals Smoother Hair Serum  (50 ml)\n",
      "Cost: 395.2000000000001\n",
      "Product Feedback: Good :- Excellent quality :- Awesome product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: Logihair INTENSIVE HAIR & SCALP SERUM ,Pack Of 1126ml)  (126 ml)\n",
      "Cost: 1152.0\n",
      "Product Feedback: Good Product Like it :- Thanks Flipkart :- very good product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: HIMALAYA Gentle Daily Care Protein Shampoo with Chickpea 200ml Each  (400 ml)\n",
      "Cost: 464.0\n",
      "Product Feedback: Very nice product product quality is very good 👍👍 :- Nice product :- Love it.\n",
      "--------------------------------------------------------------------------------\n",
      "Product: Good Hair Macadamia Nut, Avocado, Biotin Shampoo & Conditioner  (2 Items in the set)\n",
      "Cost: 852.8000000000001\n",
      "Product Feedback: Good product :- Good :- I love this product ❤️💕\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Hybrid Recommendations:\n",
      "\n",
      "Product: HIMALAYA ANTI DANDRUFF COOLING MINT SHAMPOO 400ML  (400 ml)\n",
      "Cost: 401.6\n",
      "Product Feedback: Nice quality :- wow :- Nice product,  l like the product, when i was use to feel cooling skull,but quantity is very less\n",
      "--------------------------------------------------------------------------------\n",
      "Product: TRICHUP Keratin Kit (Shampoo 200 ml, Conditioner 200 ml, Hair Cream 200 ml)  (3 Items in the set)\n",
      "Cost: 878.4000000000001\n",
      "Product Feedback: Very good :- Good product :- Thanks Flipkart nice product I love it\n",
      "--------------------------------------------------------------------------------\n",
      "Product: galway Rupabham Pro Keratin Shampoo+ Conditioner & Rupabham Pro-Keratin Hair Serum - Combo Pack  (250 ml)\n",
      "Cost: 1358.4\n",
      "Product Feedback: Fantastic product..... :- Good product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: Oshea Herbals Smoother Hair Serum  (50 ml)\n",
      "Cost: 395.2000000000001\n",
      "Product Feedback: Good :- Excellent quality :- Awesome product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: look hair Onion Oil and Onion Shampoo  (500 ml)\n",
      "Cost: 638.4000000000001\n",
      "Product Feedback: Best products thank u flipcart :- Very Good product...Thank You Flipkart Excellent :- Good product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: Logihair INTENSIVE HAIR & SCALP SERUM ,Pack Of 1126ml)  (126 ml)\n",
      "Cost: 1152.0\n",
      "Product Feedback: Good Product Like it :- Thanks Flipkart :- very good product\n",
      "--------------------------------------------------------------------------------\n",
      "Product: HIMALAYA Gentle Daily Care Protein Shampoo with Chickpea 200ml Each  (400 ml)\n",
      "Cost: 464.0\n",
      "Product Feedback: Very nice product product quality is very good 👍👍 :- Nice product :- Love it.\n",
      "--------------------------------------------------------------------------------\n",
      "Product: KESUDA Amla Premium shampoo for better hair care  (600 ml)\n",
      "Cost: 454.4\n",
      "Product Feedback: Excellent and effective product for me ,very good composition, effect on hair is best, good alovera fragrance,stop my hairfall :- This product is 100% genuine  i can feel it , it give proper during 2 month , very  very good adorable product :- Superb daily care shampoo, super fast delivery I have big problem for dandruff and dryness ,this product resolve with in three month , first time I used this product and it give perfect result\n",
      "--------------------------------------------------------------------------------\n",
      "Product: KESUDA Aloevera Amla Shampoo for better hair care  (4 L)\n",
      "Cost: 1425.6\n",
      "Product Feedback: Excellent and effective product for me ,very good composition, effect on hair is best, good alovera fragrance,stop my hairfall :- This product is 100% genuine  i can feel it , it give proper during 2 month , very  very good adorable product :- Superb daily care shampoo, super fast delivery I have big problem for dandruff and dryness ,this product resolve with in three month , first time I used this product and it give perfect result\n",
      "--------------------------------------------------------------------------------\n",
      "Product: Good Hair Macadamia Nut, Avocado, Biotin Shampoo & Conditioner  (2 Items in the set)\n",
      "Cost: 852.8000000000001\n",
      "Product Feedback: Good product :- Good :- I love this product ❤️💕\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "complete_hybrid_recommendation_workflow(main_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hairfall_risk_model_tuned_final.pkl']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, 'age_prediction_model_tuned_final.pkl')\n",
    "joblib.dump(best_model, 'hairfall_risk_model_tuned_final.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
